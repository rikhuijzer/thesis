\chapter{Introduction}
\label{ch:introduction}

\setcounter{page}{0}
\pagenumbering{arabic}
This master thesis is the final report of the graduation project for the Computer Science and Engineering master at Eindhoven University of Techonology (TU/e).
The project is carried out at Devhouse Spindle in Groningen.

\section{Thesis context}
\label{sec:thesis_context}
Spindle is interested in automatically responding to customer questions.
It is expected that automated responses to text are feasible by recent examples in artificial intelligence.
Smartphones include speech recognition, allowing users to tell the phone what they want~\citep{lopez2017alexa}.
This allows users to obtain information about the weather or the age of a specific president by talking to a device.
Self-driving car technology created by Waymo ``has driven over 10 million miles of real-world roads''~\citep{waymo2018}.
At the same time Google AlphaGo has learnt how to beat the best Go players in the world~\citep{gibney2016google} and another Google team is working on Duplex~\citep{leviathan2018google}.
The goal of Duplex is to fill in missing information from Google sites by calling people and asking for the information.
Demonstrations by Google show that it is difficult for unsuspecting humans to tell the difference between Duplex and a real human.

\iffalse
% todo: show number of publications
% field evolve speed
Remarkable about the context is the speed in which the field evolves.
Learning about some scientific topic means picking up a recent book or review paper.

For example, Stanford provides a `Deep Learning for Natural Language Processing' course.
This course is given bij Christopher Manning who has been active in natural language processing for many years and is highly cited in the field.
When comparing the material of the `Winter 2018' version with the `Winter 2017' we see many changes.
Attention and transformer models~\citep{vaswani2017attention} now get three lectures instead of one.
This could be a coincidence where last year has been a particularly interesting one.

Looking at the years before it does not seem to be so.
A recent review paper for the same field~\citep{young2018recent} still see lots of potential.
They expect better models for unlabelled data, reinforcement learning, zero-shot learning and network memory enrichment via knowledge base.

% implications of evolving speed (more hyperrefs and blog references)
The fast pace of the field implies that this thesis is in certain aspects unconventional.
An atypical high amount of references are to arXiv publications, blogposts and websites.
These sources are regarded with more than usual skepticism and it is tried to extract only empirically validated information.
Arguably the benefit of deep learning is that everyone can reproduce and improve results given some time and a (cloud) computer.
\fi

\section{Problem description}
\label{sec:problem_description}
% why intent classification
The graduation company would preferably see a system that is automatically trained on various sets of a few dozen text documents to answer customer questions.
The field working on text interpretation is natural language processing (NLP).
Research in NLP has focused their efforts on various tasks.
To solve the problem defined above we require a task which is able to interpret questions in real-time using few training data.
Natural language understanding (NLU), which maps text to meaning~\citep{jurafsky2014speech}, is working on interpretation of text.
Specifically, chatbots are using intent classification to understand the intention of a user when the user utters some sentence~\citep{bocklisch2017rasa,burtsev2018,zhou2018design}.
The IBM sales department claims that Autodesk using chatbots cut down their resolution time ``from 1.5 days to 5.4 minutes for most inquiries''~\citep{ibm2018autodesk}.

% organisations claiming highest accuracy numbers
Various parties run benchmarks and use this to draw conclusions about the best performing system.
Issues can be pointed out which question the validity of these conclusions.
A methodology and three datasets for benchmarking intent classification and named-entity recognition (NER) are created and published by~\citet{braun2017}.
NER aims to detect information like dates, locations and person names from text.
The paper compares accuracy for Microsoft LUIS~\citep{microsoft2019luis}, IBM Watson Conversation (now Watson Assistant~\citep{ibm2019assistant}), API.ai (now Google DialogFlow~\citep{google2019dialogflow}), Wit.ai~\citep{facebook2019wit}, Amazon Lex~\citep{amazon2019lex} and Rasa~\citep{bocklisch2017rasa}.
When knowing that the field is rapidly advancing~\citep{young2018recent} it becomes clear that the scores from this paper are outdated.
Snips~\citep{snips2019voice} show that they outperform the competition by a large margin~\citep{snips2017benchmarking}.
The competition consists of api.ai, Wit.ai, Luis.ai and Amazon Alexa.
Their small benchmark tests the systems against 70 queries per intent on their own dataset.
Snips claim to score 79\% accuracy, while the second best scores 73\%.
Also, via sentence examples Snips show that some named-entities are classified incorrectly by systems other than Snips.
Although the authors ``guarantee transparency'' about the benchmark~\citep{snips2017dataset}, the dataset could still be cherry picked.
DeepPavlov~\citep{burtsev2018} reports another high score for intent classification.
It is based on the Snips dataset~\citep{snips2017dataset} and compared against API.ai, Watson Conversation, Microsoft LUIS, Wit.ai, Snips, Recast.ai (now SAP Conversational AI~\citep{sap2019conversational}) and Amazon Lex.
Their model uses embeddings trained on the DSTC2 dataset~\citep{baymurzina2019classifiers,baymurzina2019intents}.
DSTC2 contains communications with users or `calls'~\citep{henderson2014second}.
The dataset includes roughly 500 dialogs with 7.88 turns on average in each condition for 6 conditions~\citep{henderson2014second}, hence about 20.000 turns or utterances.
Knowing that the focus for Snips also lies in interpretation of voice commands~\citep{snips2019voice} it is expected that the model created by DeepPavlov does not obtain state-of-the-art results for other datasets.
Botfuel~\citep{botfuel2019} claims to be `on par' with the competition~\citep{botfuel2018benchmark}.
This is based on runs on the same datasets as~\citet{braun2017}.
Botfuel shows it is one procent lower than Watson, equals LUIS and outperforms DialogFlow, Rasa, Snips and Recast.ai.
The score for Rasa matches the score listed by~\citet{braun2017}.
This means that Botfuel has compared their system against an old version of Rasa.
These observations give rise to the following research question.\\

\rqone \\[1mm]

An interesting problem from an academic point of view is increasing accuracy.
The second research question aims to do that.\\

\rqtwo \\[1mm]

For the graduation company Dutch datasets would match their use-case, however the focus in NLP research is on English datasets~\citep{cambria2014jumping,young2018recent}.
To be able to compare our results this thesis will also focus on English datasets.
It is expected that the knowledge from answering this question can be transferred to Dutch datasets since modern multilingual models exist~\citep{spacy2019models,subramanian2018learning,devlin2018}.
The first and second research question are discussed respectively in chapter~\ref{ch:benchmarking} and~\ref{ch:improving_accuracy}.

\section{Project goal}
\label{sec:project_goal}
Answering RQ1 means writing code.
Even if the answer is negative, it will have provided a baseline to use when answering RQ2.
The aim of the software is to be used by others, so it should be easy to run.
Software extensions should also be possible.
The goal related to the first research question is as follows.\\

\rgone \\

\noindent To not let our guard down the goal related to the second research question is stated ambitiously.\\

\rgtwo