\chapter{Introduction}
\label{ch:introduction}

\setcounter{page}{0}
\pagenumbering{arabic}
This master thesis is the final report of the graduation project for the Computer Science and Engineering master at Eindhoven University of Techonology (TU/e).
The project is carried out at Devhouse Spindle in Groningen.
In this chapter the research questions are presented.
Section~\ref{sec:thesis_context} explains the context for the research problem.
The problem and the research questions are discussed in Section~\ref{sec:problem_description}.
Resulting goals from these questions are listed in Section~\ref{sec:project_goal} as is an outline for the rest of the thesis.

\section{Thesis context}
\label{sec:thesis_context}
Spindle is interested in automatically responding to customer questions.
The field working on text interpretation is natural language processing (NLP).
It is expected that automated responses to text are feasible by recent examples in artificial intelligence.
Smartphones include speech recognition, allowing users to control the device using speech~\citep{lopez2017alexa}.
For example, users can obtain information about the weather or the age of a specific president by talking to the device.
Self-driving car technology created by Waymo ``has driven over 10 million miles of real-world roads''~\citep{waymo2018}.
At the same time Google AlphaGo has learnt how to beat the best Go players in the world~\citep{gibney2016google} and another Google team is working on Duplex~\citep{leviathan2018google}.
The goal of Duplex is to fill in missing information from Google sites by calling people and asking for the information.
Demonstrations by Google show that it is difficult for unsuspecting humans to tell the difference between Duplex and a real human.

% field evolve speed
Remarkable about the context is the speed in which the field evolves.
Picking up a book as recent as 2010 will not list many common practises applied nowadays.
The newer NLP approaches use deep learning (to do NLP from scratch) as introduced by~\citet{collobert2011natural} in 2011.
In 2013 vector representations for words became dense by the introduction of word2vec~\citep{mikolov2013distributed}.
These dense vectors have been ``producing superior results on various NLP tasks''~\citep{young2018recent}.

% implications of evolving speed (more hyperrefs and blog references)
The fast pace of the field and the popularity of machine learning causes this thesis to be in certain aspects unconventional.
The benefit of deep learning is that everyone can reproduce and improve results given some time and a (cloud) computer.
The fast pace and machine learning cause an atypical high amount of references to respectively arXiv publications and blogposts and websites.
It is tried to regard these sources with more than usual skepticism.

\section{Problem description}
\label{sec:problem_description}
% why intent classification
Spindle would want to see a system that is automatically trained on various sets of a few dozen text documents to answer customer questions.
Research in NLP has focused their efforts on various tasks.
To solve the problem defined above, we require a task which is able to interpret questions in real-time using little training data.
Natural language understanding (NLU), which maps text to its meaning~\citep{jurafsky2014speech}, is working on interpretation of text.
Specifically, chatbots are using intent classification to understand the intention of a user when the user utters some sentence~\citep{bocklisch2017rasa,burtsev2018,zhou2018design}.
The IBM sales department claims that Autodesk using chatbots cut down their resolution time ``from 1.5 days to 5.4 minutes for most inquiries''~\citep{ibm2018autodesk}.

% organisations claiming highest accuracy numbers
Various parties run benchmarks and use this to draw conclusions about the best performing system.
Issues can be pointed out which question the validity of these conclusions.
A methodology and three datasets for benchmarking intent classification and named-entity recognition (NER) are created and published by~\citet{braun2017}.
NER aims to detect information like dates, locations and person names from text.
The paper compares accuracy for Microsoft LUIS~\citep{microsoft2019luis}, IBM Watson Conversation (now Watson Assistant~\citep{ibm2019assistant}), Api.ai (now Google DialogFlow~\citep{google2019dialogflow}), Wit.ai~\citep{facebook2019wit}, Amazon Lex~\citep{amazon2019lex} and Rasa~\citep{bocklisch2017rasa}.
When knowing that the field is rapidly advancing~\citep{young2018recent} it becomes clear that the scores from this paper are outdated.
Snips~\citep{snips2019voice} show that they outperform the competition by a large margin~\citep{snips2017benchmarking}.
The competition consists of Api.ai, Wit.ai, Luis.ai and Amazon Alexa (now Amazon Lex~\citep{amazon2019lex}).
Their small benchmark tests the systems against 70 queries per intent on their own dataset.
Snips claim to score 79\% accuracy, while the second best scores 73\%.
Also, via sentence examples Snips show that some named-entities are classified incorrectly by systems other than Snips.
Although the authors ``guarantee transparency'' about the benchmark~\citep{snips2017dataset}, the dataset could still be cherry-picked.
DeepPavlov~\citep{burtsev2018} reports another high score for intent classification.
It is based on the Snips dataset~\citep{snips2017dataset} and compared against Api.ai, Watson Conversation, Microsoft LUIS, Wit.ai, Snips, Recast.ai (now SAP Conversational AI~\citep{sap2019conversational}) and Amazon Lex.
Their model uses embeddings trained on the DSTC2 dataset~\citep{baymurzina2019classifiers,baymurzina2019intents}.
DSTC2 contains communications with users or `calls'~\citep{henderson2014second}.
The dataset includes roughly 500 dialogs with 7.88 turns on average in each condition for 6 conditions~\citep{henderson2014second}, hence about 20.000 turns or utterances.
Knowing that the focus for Snips also lies in interpretation of voice commands~\citep{snips2019voice} it is expected that the model created by DeepPavlov does not obtain state-of-the-art results for other datasets.
Botfuel~\citep{botfuel2019} claims to be `on par' with the competition~\citep{botfuel2018benchmark}.
This is based on runs on the same datasets as~\citet{braun2017}.
Botfuel shows it is one procent lower than Watson, equals LUIS and outperforms DialogFlow, Rasa, Snips and Recast.ai.
The score for Rasa matches the score listed by~\citet{braun2017}.
This means that Botfuel has compared their system against an old version of Rasa.
These observations give rise to the following research question.\\

\rqone \\[1mm]

An interesting problem from an academic point of view is increasing accuracy.
The second research question aims to do that.\\

\rqtwo \\[1mm]

For the graduation company Dutch datasets would match their use-case, however the focus in NLP research is on English datasets~\citep{cambria2014jumping,young2018recent}.
To be able to compare our results this thesis will also focus on English datasets.
It is expected that the knowledge from answering this question can be transferred to Dutch datasets since modern multilingual models exist~\citep{spacy2019models,subramanian2018learning,devlin2018}.
The first and second research question are discussed respectively in Chapter~\ref{ch:benchmarking} and~\ref{ch:improving_accuracy}.

\section{Project goal and outline}
\label{sec:project_goal}
Answering RQ1 means writing code.
Even if the answer is negative, it will have provided a baseline to use when answering RQ2.
The aim of the software is to be used by others, so it should be easy to run.
Software extensions should also be possible.
The goal related to the first research question is as follows.\\

\rgone \\

\noindent The goal related to the second research question is stated ambitiously.\\

\rgtwo \\

% outline
The first research question is discussed in Chapter~\ref{ch:benchmarking}.
NLP and NLU are introduced in detail in Chapter~\ref{ch:preliminaries}, specifically in Section~\ref{sec:nlp}.
The second research question is discussed in Chapter~\ref{ch:improving_accuracy}.
To be able to compare the introduced deep learning model with existing models one need to know about the existing models.
Well-known models in NLP are explained in Chapter~\ref{ch:preliminaries}, specifically in Section~\ref{sec:deep_learning}.