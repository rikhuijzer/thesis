\chapter{Introduction}
\label{ch:introduction}

\setcounter{page}{0}
\pagenumbering{arabic}
This master thesis is the final report of the graduation project for the Computer Science and Engineering master at Eindhoven University of Techonology (TU/e).
The project is carried out at Devhouse Spindle in Groningen.

\section{Thesis context}
\label{sec:thesis_context}
Spindle is interested in automatically responding to customer questions.
It is expected that automated responses to text are feasible by recent examples in artificial intelligence.
Smartphones include speech recognition, allowing users to tell the phone what they want~\citep{lopez2017alexa}.
This allows users to obtain information about the weather or the age of a specific president by talking to a device.
Self-driving car technology created by Waymo ``has driven over 10 million miles of real-world roads''~\citep{waymo2018}.
At the same time Google AlphaGo has learnt how to beat the best Go players in the world~\citep{gibney2016google} and another Google team is working on Duplex~\citep{leviathan2018google}.
The goal of Duplex is to fill in missing information from Google sites by calling people and asking for the information.
Demonstrations by Google show that it is difficult for unsuspecting humans to tell the difference between Duplex and a real human.

\iffalse
% todo: show number of publications
% field evolve speed
Remarkable about the context is the speed in which the field evolves.
Learning about some scientific topic means picking up a recent book or review paper.

For example, Stanford provides a `Deep Learning for Natural Language Processing' course.
This course is given bij Christopher Manning who has been active in natural language processing for many years and is highly cited in the field.
When comparing the material of the `Winter 2018' version with the `Winter 2017' we see many changes.
Attention and transformer models~\citep{vaswani2017attention} now get three lectures instead of one.
This could be a coincidence where last year has been a particularly interesting one.

Looking at the years before it does not seem to be so.
A recent review paper for the same field~\citep{young2018recent} still see lots of potential.
They expect better models for unlabelled data, reinforcement learning, zero-shot learning and network memory enrichment via knowledge base.

% implications of evolving speed (more hyperrefs and blog references)
The fast pace of the field implies that this thesis is in certain aspects unconventional.
An atypical high amount of references are to arXiv publications, blogposts and websites.
These sources are regarded with more than usual skepticism and it is tried to extract only empirically validated information.
Arguably the benefit of deep learning is that everyone can reproduce and improve results given some time and a (cloud) computer.
\fi

\section{Problem description}
\label{sec:problem_description}
% why intent classification
The graduation company would preferably see a system that is automatically trained on various sets of a few dozen text documents to answer customer questions.
The field working on text interpretation is natural language processing (NLP).
Research in NLP has focused their efforts on various tasks.
To solve the problem defined above we require a task which is able to interpret questions in real-time using few training data.
Natural language understanding (NLU), which maps text to meaning~\citep{jurafsky2014speech}, is working on interpretation of text.
Specifically, chatbots are using intent classification to understand the intention of a user when uttering some sentence~\citep{a, b, c, d}.
The IBM sales department claims that Autodesk using chatbots cut down their resolution time ``from 1.5 days to 5.4 minutes for most inquiries''~\citep{ibm2018autodesk}.

% organisations claiming highest accuracy numbers
Various organisations claim to have obtained the best accuracy numbers for text classification tasks.
Snips show that they outperform the competition by a large margin (\url{https://medium.com/snips-ai/2b8ddcf9fb19}) on 2 June 2017.
The competition consists of api.ai (now Google DialogFlow~\citep{google2019dialogflow}), Wit.ai, Luis.ai~\citep{microsoft2019luis} and Amazon Alexa (now Amazon Lex~\citep{amazon2019lex}).
Their small benchmark tests the systems against 70 queries per intent on their own dataset.
Snips claim to score 79\% accuracy, while the second best scores 73\%.
Also, via sentence examples Snips show that some named-entities are classified incorrectly by systems other than Snips.
A comparison by~\citet{braun2017} looks at LUIS, Watson Conversation, API.ai, wit.ai, Amazon Lex and Rasa.
Three datasets are created and published by the authors.
Code to re-run or extend the benchmarks has not been included.
DeepPavlov~\citep{burtsev2018} reports another high score for intent classification.
It is based on the Snips dataset and compared against api.ai, Watson Conversation, Microsoft LUIS, Wit.ai, Snips.ai, Recast.ai and Amazon Lex.
Botfuel show they are `on par' with the competition (\url{https://medium.com/botfuel/eb8684a1e55f}).
This is based on runs on the same datasets as~\citet{braun2017}.
Using micro averaging the Botfuel is one procent lower than Watson, equals LUIS and outperforms DialogFlow, Rasa, Snips and Recast.
The results for Rasa match the results provided in the paper.
This means that Botfuel has compared their system against an old version of Rasa.

% bench problem generalization
The main problem with these claims is that the numbers appear convincing to a machine learning layman.
It could be that some organisation has cherry picked a dataset for their system or omitted systems which outperformed theirs.
The only way for users to determine what system is the most accurate for their data is to trust these claims or write their own benchmark.
This gives rise to the following research question.\\

\rqone \\[1mm]

% increasing state of the art problem
Another interesting problem from an academic point of view is increasing accuracy.
Natural language understanding is far from solved.
Due to the probabilistic nature of machine learning one should not expect perfect results.
However, accuracies one some computer vision tasks are above 99\%, which cannot be said for natural language understanding.
The second research question is as follows.\\

\rqtwo \\[1mm]

The focus in this question lies on English datasets.
For Spindle Dutch datasets would be more useful, however baselines for Dutch datasets do not exist.
Also, knowledge obtained from answering RQ2 is expected to generalise to any language.
The first and second research question are discussed respectively in chapter~\ref{ch:benchmarking} and~\ref{ch:improving_accuracy}.

\section{Project goal}
\label{sec:project_goal}
Answering RQ1 means writing code.
Even if the answer is negative, it will have provided a baseline to use when answering RQ2.
The aim of the software is to be used by others, so it should be easy to run.
Software extensions should also be possible.
The goal related to the first research question is as follows.\\

\rgone \\

\noindent To not let our guard down the goal related to the second research question is stated ambitiously.\\

\rgtwo